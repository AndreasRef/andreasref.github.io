<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Superpeter</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            color: white;
            background-color: #0C120E;
        }
        h1 {
            margin: 20px 0;
            font-size: 56px;
        }
        #controls {
            display: flex;
            justify-content: center;
            margin-bottom: 10px;
        }
        #conversation {
            border: 1px solid #ccc;
            padding: 10px;
            width: 90%;
            max-width: 600px;
            height: 400px;
            overflow-y: scroll;
        }
        .message {
            margin: 5px 0;
        }
        .user {
            font-weight: bold;
        }
        .bot {
            font-style: italic;
        }
        .system {
            color: gray;
        }
        .hidden {
            display: none;
        }

        #prompt-editor {
            width: 90%;
            max-width: 600px;
            height: 150px; /* Adjust this value to make the editor larger */
            margin: 10px;
        }

        @media (max-width: 600px) {
            #conversation {
                height: 300px;
            }
        }

        #webcam-feed, canvas {
            margin: 20px;
            width: 90%;
            max-width: 600px;
            height: auto;
            display: none;
        }
    </style>
</head>
<body>
    <h1>Superpeter</h1>
    
    <img src="Peter-Werner-03-COVER-scaled.jpg" alt="Peter Werner Cover Image" style="max-width: 90%; height: auto; margin-bottom: 20px;">
    
    <div id="controls">
        <button id="start-btn">Start</button>
        <button id="stop-btn" disabled>Stop</button>
        <button id="toggle-prompt-btn">Sæt instruktioner</button>
        <button id="save-conversation-btn">Gem samtale</button>
        <button id="toggle-video-btn">Tænd video</button>
    </div>
    <video id="webcam-feed" autoplay></video>
    <canvas id="webcam-canvas" style="display: none;"></canvas>
    <textarea id="prompt-editor" class="hidden"></textarea>
    <div id="conversation"></div>
    <audio id="audio-player"></audio>
    <script>
        
        function getQueryParameter(name) {
            const urlParams = new URLSearchParams(window.location.search);
            return urlParams.get(name);
        }

        const OPENAI_API_KEY = getQueryParameter('openai_api_key');
        const XI_API_KEY = getQueryParameter('xi_api_key');

        if (!OPENAI_API_KEY || !XI_API_KEY) {
            document.body.innerHTML = '<p>API Keys are not found in the URL.</p>';
            throw new Error('API Keys are not found in the URL.');
        }

    const toggleVideoBtn = document.getElementById('toggle-video-btn');
    const webcamFeed = document.getElementById('webcam-feed');
    const webcamCanvas = document.getElementById('webcam-canvas');
    const webcamContext = webcamCanvas.getContext('2d');
    let webcamStream = null;
    let videoOn = false;

    toggleVideoBtn.addEventListener('click', async () => {
        if (webcamFeed.style.display === 'none') {
            try {
                webcamStream = await navigator.mediaDevices.getUserMedia({ video: true });
                webcamFeed.srcObject = webcamStream;
                webcamFeed.style.display = 'block';
                toggleVideoBtn.textContent = 'Sluk video';
                requestAnimationFrame(drawWebcamToCanvas);
                videoOn = true;
                console.log("videoOn: "+ videoOn)
            } catch (error) {
                console.error('Error accessing webcam:', error);
            }
        } else {
            if (webcamStream) {
                webcamStream.getTracks().forEach(track => track.stop());
            }
            webcamFeed.srcObject = null;
            webcamFeed.style.display = 'none';
            webcamCanvas.style.display = 'none';
            toggleVideoBtn.textContent = 'Tænd video';
            videoOn = false;
            console.log("videoOn: "+ videoOn)
        }
    });

    function drawWebcamToCanvas() {
        if (webcamFeed.style.display !== 'none') {
            webcamCanvas.width = webcamFeed.videoWidth;
            webcamCanvas.height = webcamFeed.videoHeight;
            webcamContext.drawImage(webcamFeed, 0, 0, webcamCanvas.width, webcamCanvas.height);
            webcamCanvas.style.display = 'hide';
            requestAnimationFrame(drawWebcamToCanvas);
        }
    }

    // Set initial state
    webcamFeed.style.display = 'none';
    toggleVideoBtn.textContent = 'Tænd video';


        const startBtn = document.getElementById('start-btn');
        const stopBtn = document.getElementById('stop-btn');
        const togglePromptBtn = document.getElementById('toggle-prompt-btn');
        const saveConversationBtn = document.getElementById('save-conversation-btn');
        const conversationElem = document.getElementById('conversation');
        const promptEditor = document.getElementById('prompt-editor');
        const audioPlayer = document.getElementById('audio-player');

        let recognition;
        let conversationHistory = [
            { role: 'system', content: `
**Identitet:**\n
- Dit navn er Peter Werner Kuhn Henriksen.\n
- Du er 30 år gammel og er opvokset i Padborg.\n
- Du har tidligere arbejdet som soldat og telefonsælger, og nu er du komiker.\n
- Du ved en hel masse om kaffesirup\n\n
**Formål:**\n
- Dit hovedmål er at tale med Peters kæreste, Clara.\n
- Du skal være sød, empatisk, og lyttende, når du taler med Clara.\n\n
**Kommunikationsstil:**\n
- Vær altid opmærksom, vis interesse og vær støttende.\n
- Sørg for at anerkende hendes følelser og validere hendes oplevelser.\n
- Brug en afslappet og venlig tone, som er karakteristisk for en kærlig kæreste.\n
- Giv relativt korte svar, men sørg for at dine svar er meningsfulde og fulde af empati.\n\n
**Interaktioner med Clara:**\n
- Spørg hende ind til hendes hverdag og lyt aktivt til hendes svar.\n
- Vis oprigtig interesse, især når hun deler dybere tanker om sin baggrund, drømme og ambitioner.\n
- Stil opfølgende spørgsmål for at vise, at du lytter og bryder dig om, hvad hun deler.\n
- Ros hendes præstationer og opmuntre hende i hendes bestræbelser.\n
- Forsøg at finde små måder at støtte hende på følelsesmæssigt.\n\n
**Eksempler på samtaleemner:**\n
- Spørg Clara, hvordan hendes dag har været.\n
- Spørg ind til hendes arbejde eller studier og hvad hun synes om det.\n
- Lyt til hendes tanker om fremtiden og hendes drømme.\n
- Anerkend hendes følelser og vær en opmuntrende og positiv støtte.\n
- Del også gerne små anekdoter fra din dag, specielt hvis de kan få hende til at grine eller føle sig bedre tilpas.\n\n
**Eksempler på formuleringer:**\n
- "Hvordan har din dag været, skat?"\n
- "Det lyder virkelig spændende, vil du fortælle mig mere om det?"\n
- "Det må have været hårdt, hvordan har du det med det?"\n
` }
        ];

        startBtn.addEventListener('click', startRecording);
        stopBtn.addEventListener('click', stopRecording);
        togglePromptBtn.addEventListener('click', togglePromptEditor);
        saveConversationBtn.addEventListener('click', saveConversation);

        function startRecording() {
            recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
            recognition.lang = 'da-DK';
            recognition.interimResults = false;  // Enable interim results
            recognition.continuous = true;      // Keep the recognition service running
            recognition.maxAlternatives = 1;

            recognition.onstart = () => {
                //startBtn.disabled = true;
                startBtn.disabled = false;
                stopBtn.disabled = false;
                addMessage('System', 'Lytter...');
            };

            recognition.onresult = async (event) => {
                const transcription = event.results[0][0].transcript;
                console.log(`User Prompt: ${transcription}`);
                addMessage('Dig', transcription);
                conversationHistory.push({ role: 'user', content: transcription });

                try {
                    let gptResponse;

                    if (videoOn) { // Assume `webcamOn` is a boolean indicating webcam status
                        const image = await captureWebcamImage(); // Placeholder function to capture image from webcam
                        gptResponse = await generateVisionResponse(conversationHistory, image);
                    } else {
                        gptResponse = await generateResponse(conversationHistory);
                    }

                    console.log(`GPT Response: ${gptResponse}`);
                    addMessage('Superpeter', gptResponse);
                    conversationHistory.push({ role: 'assistant', content: gptResponse });

                    await playText(gptResponse);
                } catch (error) {
                    console.error('Error during processing:', error);
                }

                recognition.stop();
            };

            async function captureWebcamImage() {
                let imageData;
                imageData = webcamCanvas.toDataURL('image/jpeg');
                // Placeholder for actual implementation to capture an image from the webcam
                console.log('Capturing image from webcam...');
                console.log(imageData);
                return imageData;
            }

            recognition.onerror = (event) => {
                if (event.error === 'no-speech') {
                    recognition.start(); // Restart recognition on no-speech error
                } else {
                    console.error('Speech recognition error:', event.error);
                    startBtn.disabled = false;
                    stopBtn.disabled = true;
                }
            };

            recognition.onend = () => {
                addMessage('System', 'Lytter ikke mere... Tryk på start, for at lytte igen.');
                console.log("Recording stopped")
            };

            recognition.start();
        }

        function stopRecording() {
            recognition.stop();
            startBtn.disabled = false;
            stopBtn.disabled = true;
            //addMessage('System', 'Recording stopped...');
            console.log("Recording stopped")
        }

        async function generateResponse(conversation) {
            const response = await fetch('https://api.openai.com/v1/chat/completions', {
                method: 'POST',
                headers: {
                    'Authorization': `Bearer ${OPENAI_API_KEY}`,
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    model: 'gpt-4o',
                    messages: conversation,
                    max_tokens: 500
                })
            });

            if (!response.ok) {
                throw new Error(`GPT API error: ${response.statusText}`);
            }
            
            const data = await response.json();
            return data.choices[0].message.content.trim();
        }

        async function generateVisionResponse(conversation, imageData) {
            let returnText = "Intet svar fra API'en"
            const base64Image = imageData.split(',')[1]; // Remove the Data URL prefix
            console.log('Generating vision response...');
            // Placeholder for actual implementation

            const prompt = "";
            //conversation.push({ role: "user", content: "Svar på min sidste besked, men forhold dig samtidig til billedet, som er det du ser lige nu." });
            //conversation.push({ role: "image", content: `data:image/jpeg;base64,${imageData}`, detail: "low" });
            conversation.push({
                role: "user",
                content: [
                    { type: "text", text: "Svar på min sidste besked, men forhold dig samtidig til billedet, som er det, du ser lige nu. Gør det naturligt, som om du er der, og udgå at benytte ordet billede." },
                    { type: "image_url", image_url: { url: `data:image/jpeg;base64,${base64Image}`, detail: "low" } }
                ]
            });

            const payload = {
                model: "gpt-4o",
                
                messages: conversation,
                // messages: [
                //     {
                //         role: "user",
                //         content: [
                //             {
                //                 type: "text",
                //                 text: prompt
                //             },
                //             {
                //                 type: "image_url",
                //                 image_url: {
                //                     url: `data:image/jpeg;base64,${base64Image}`,
                //                     detail: "low"
                //                 }
                //             }
                //         ]
                //     }
                // ],
                max_tokens: 500
            };

            console.log('Request payload:', JSON.stringify(payload));
            //statusDiv.textContent = "Sending request...";

            try {
                const response = await fetch("https://api.openai.com/v1/chat/completions", {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${OPENAI_API_KEY}`
                    },
                    body: JSON.stringify(payload)
                });

                if (!response.ok) {
                    const error = await response.json();
                    console.error('Error response:', error);
                    throw new Error(`Error: ${error.message}`);
                }

                const result = await response.json();
                console.log('Response received:', result);
                console.log('Content', result.choices[0].message.content);
                returnText = result.choices[0].message.content;
                //document.getElementById('chatOutput').innerText = result.choices[0].message.content;
                //statusDiv.textContent = "Request completed.";
            } catch (error) {
                console.error('Error:', error);
                returnText = "Hov, der skete en fejl med billedet."
                //statusDiv.textContent = "Error occurred.";
            }
            return returnText; 
        }


        async function playText(text) {
            //addMessage('System', 'Generating audio...');
            console.log("Generating audio...")

            var options = {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'xi-api-key': XI_API_KEY
                },
                body: JSON.stringify({
                    text: text,
                    voice_settings: {
                        similarity_boost: 0.5,
                        stability: 0.5,
                        use_speaker_boost: true,
                        style: 0.74
                    },
                    model_id: "eleven_multilingual_v2",
                    output_format: "mp3_44100_128"
                })
            };

            const response = await fetch('https://api.elevenlabs.io/v1/text-to-speech/inl8zfvv6wiqUqSdxQUv', options);

            if (!response.ok) {
                throw new Error(`ElevenLabs API error: ${response.statusText}`);
            }

            const blob = await response.blob();
            const url = URL.createObjectURL(blob);
            audioPlayer.src = url;
            audioPlayer.play();

            audioPlayer.onplay = () => {
                //addMessage('System', 'Playing response...');
                console.log("Playing response...")
                stopRecording();
            };

            audioPlayer.onended = () => {
                //addMessage('System', 'Playback ended. Resuming recording...');
                console.log("Playback ended. Resuming recording...")
                startRecording();
            };
        }

        function addMessage(sender, text) {
            const messageElem = document.createElement('div');
            messageElem.className = 'message';
            messageElem.classList.add(sender.toLowerCase());
            messageElem.textContent = `${sender}: ${text}`;
            conversationElem.appendChild(messageElem);
            conversationElem.scrollTop = conversationElem.scrollHeight; // Scroll to the bottom
        }

        function togglePromptEditor() {
            if (promptEditor.classList.contains('hidden')) {
                promptEditor.value = conversationHistory.find(msg => msg.role === 'system').content;
                promptEditor.classList.remove('hidden');
                togglePromptBtn.textContent = 'Save Prompt';
            } else {
                conversationHistory = conversationHistory.map(msg => {
                    if (msg.role === 'system') {
                        return { role: 'system', content: promptEditor.value };
                    }
                    return msg;
                });
                promptEditor.classList.add('hidden');
                togglePromptBtn.textContent = 'Edit Prompt';
                addMessage('System', 'Prompt updated.');
            }
        }

        function saveConversation() {
            const conversationText = conversationHistory.map(msg => `${msg.role}: ${msg.content}`).join('\n');
            console.log(`Conversation: ${conversationText}`);

            if (navigator.userAgent.match(/Android|iPhone|iPad|iPod/i)) {
                navigator.clipboard.writeText(conversationText)
                    .then(() => alert('Conversation copied to clipboard'))
                    .catch(err => console.error('Could not copy text: ', err));
            } else {
                const blob = new Blob([conversationText], { type: 'text/plain' });
                const url = URL.createObjectURL(blob);
                const a = document.createElement('a');
                a.href = url;
                a.download = 'conversation.txt';
                document.body.appendChild(a);
                a.click();
                document.body.removeChild(a);
                URL.revokeObjectURL(url);
                alert('Conversation saved as conversation.txt');
            }
        }
    </script>
</body>
</html>
