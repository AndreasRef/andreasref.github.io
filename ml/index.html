
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Machine Learning Workshop @AndreasRef</title>
        <meta name="robots" content="noindex, nofollow">
        <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:300,700" rel="stylesheet">
        <link rel="stylesheet" href="main.css">
    </head>
    <body>
        <div id="wrapper">
        
            <h1>Machine Learning Workshop @AndreasRef</h1>
            
<!--
            <p><a href="https://we.tl/t-BIxn8Ko4Ga" target="_blank">Andreas intro slides</a></p>

            <p><a href="https://docs.google.com/document/d/1LhUepnOQmyknlATbGRzNk1bStdoW56GvmA7GekxsBgE/edit?usp=sharing" target="_blank">Summary of Tools</a></p>
-->
            
        

            <section>           
<!--
                <h1>Runway Examples for Processing</h1>
                <h3><a href="RunwayProcessingExamples.zip">Download zip</a></h3>
                <br>
-->
                
                <h1>Day 1) ml5js</h1>
                <h2>Templates, examples and exercises</h2>
                <br>
                
                <h3>0) p5js online editor</h3>
                <ul><a href="https://editor.p5js.org/">Setup an account with the p5js online editor</a></ul>
                <br>

                <h3>1) Train a classification algorithm</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_mobilenet.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/BJkaHBMYm">Simple template: Webcam classifier </a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/rJqk5_1aX">Webcam classifier + image</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/ryLlIOJpX">Webcam classifier + sound</a></ul>
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/B19EA7x6Q">Webcam classifier + filter</a></ul>-->
                
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/I0qqnPjfe">Webcam classifier w. 4 classes + save and load</a></ul>
                
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/BynhuHsqX">Advanced example: Trainable Camera</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/lUELywyf4">Advanced example: Image Classifier flexible classes + load/save</a></ul>

                <ul><em>Exercise 1 (individual): Train a classifier to distinguish between two different classes. Make the sketch output a descriptive text (or a visual or sound if you are more advanced) for each class.</em></ul>
                <br>


                <h3>2) MobileNet pretrained classification</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_classifier.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/H1L-KrzFQ">Simple template: Mobilenet pretrained classification</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/Sk8M6mqh7">Advanced example: Classification to speech</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/present/AYNNRbR9A">Advanced example: Poems about things</a> -> <a href ="http://andreasrefsgaard.dk/project/poems-about-things/">About the project</a></ul>
                <ul><a href="https://github.com/ml5js/ml5-library/blob/master/src/utils/IMAGENET_CLASSES.js">ImageNet list of classes</a></ul>
                
                <ul><em>Exercise 2 (group): Pick an object (or a few objects) for the model to recognise. Make something happen when your object(s) gets detected.</em></ul>
                <br>

                <h3>3) Train a regression algorithm</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_regression.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/cN6Oebzur">Simple template: Webcam regressor</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/HyEDToYnQ">Advanced example: Playback rate camera</a></ul>
                <ul><em>Exercise 3 (individual): Train the regressor and use the continuous output value to control something. It is okay to leave the code as it is, and just focus on training the system.</em></ul>
                <br>

                <h3>4) PoseNet pose detection</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_posenet.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/rkz42BzYQ">Simple template: Webcam PoseNet </a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/RLv1QbuLa">Advanced example: Classify poses</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/r1_w73FhQ">Advanced example: Draw with your nose</a></ul>
                <ul><em>Exercise 4 (group): A) Use the x-y value of a bodypart to control something or B) Use "Classify poses" as a starting point and make something happen for the different poses.</em></ul>
                <br>
                
                <h3>5) Beyond ml5js: Sound, speech and face</h3>
                <ul><img src="face_emotions.png"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/5DHTu_cQm">KNN MFCCs sound classification (with meyda.js)</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/DTNxwVdxf">Speech recognition (with annyang.js)</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/2ElDbMuHT">Pretrained Facial Emotions (with clm tracker)</a></ul>
                <ul><a href="https://andreasref.github.io/kochi/face_knn/index.html">KNN Facial Expressions (not in p5js editor - takes 30 seconds to load)</a> -> <a href="https://andreasref.github.io/ml5js/face_knn.zip">download zip</a> </ul>
                
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/25DZ20Onw">KNN Facial Expressions (with clm tracker)</a></ul>-->
                <br>
                
                <ul><em>Exercise 5 (group): Use one of the three templates above as a starting point for making an interactive sketch that you control with sounds, speech or facial expressions.</em></ul>
                <br>
                
                <ul><em>Exercise 6 (individual): <br>Come up with as many ideas as possible for projects that can be build using the techniques you have learned so far in 20 minutes. You MUST make a least 10 ideas, and at least 1 idea for each of the five headlines: <br> 1) Train your own classification <br> 2) Pretrained classification <br> 3) Regression <br> 4) PoseNet <br> 5) Sound, speech and face <br><br> Each idea should be written on a single small post-it.</em></ul>
                <br>
                
                <ul><em>Exercise 7 (work in pairs): <br>Share all your ideas with the person next to you and discuss them. <br> It is okay to come up with more ideas and build on top of each others ideas as you share. <br> In the end pick the best three ideas per person, redo them on a big post-it with a clear descriptive title + a small sketch, so they are easy to read and understand and bring the ideas tomorrow. </em></ul>
                <br>

                <h3>Other links</h3>
                <ul><a href="https://ml5js.org/docs/quick-start">Documentation + more examples on ml5js.org</a></ul>        
                <ul><a href="https://js.tensorflow.org/" target="_blank">Tensorflow.js website</a></ul>
                <ul><a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a></ul>
                <ul><a href="https://booksby.ai/" target="_blank">Books by AI</a></ul>
                

                <br>
                <ul><a href="https://editor.p5js.org/" target="_blank">Official p5.js editor</a></ul>
                <ul><a href="https://p5js.org/reference/" target="_blank">Official p5.js reference</a></ul>
                <ul><a href="https://andreasref.github.io/malmedkodning/index.html" target="_blank">Examples for p5.js aimed at beginners</a></ul>    
    
                <br>
            </section>
            
            


            
            <section>
                <h1>Day 2: Runway</h1>
                
                <h2>Required downloads</h2>
                <ul>
                    <li>
                        <a href="https://runwayapp.ai/beta/get/">Runway</a>
                        <p>Download and install Runway. You should have recieved an invitation over email. Use that email address to set up your account. If you haven't <a href="mailto:mail@andreasrefsgaard.dk">let us know!</a></p>
                        <p>Please follow the <a href="https://docs.runwayapp.ai/#/installation">Installation guide</a> to make sure you are all setup (and have Docker running) before we start.</p>
                        <p>Once Runway is installed with Docker, you can install the models you want to play with in the workshop. Install <strong>im2txt</strong> (required) and any other models you feel like and have space for on your computer. See step 1 and 2 from <a href="https://docs.runwayapp.ai/#/tutorial_t2i">this tutorial</a> for how to install models.</p>
                        
                        <p><a href="sampleImages.zip">Small zip with mixed images from ImageNet</a></p>
                        
                    </li>
                </ul>
                <br>
                
                <h2>Exercises</h2>
                
                <ul><strong>Exercise 1 (individual):</strong><br> Find 10 images either online or on your computer that you want to run through the different models in Runway and place them in a folder. Try to pick images that are not all too similar, and perhaps pick different styles of images (press photos, paintings, images from pop culture, personal photos).</ul>
                <br>
                
                <ul><strong>Exercise 2 (pairs): im2txt -> AttnGAN</strong><br>1) Use your images as input to im2txt. <br>2) Use the line of text from im2txt as input for AttnGAN. <br>3) Document interesting combinations.</ul>
                <br>
                
                <ul><strong>Exercise 3 (pairs): AttnGAN -> im2xt </strong><br>1) Write a sentence and make AttnGAN output an image. <br>2) Save the image to your computer. <br>3) Feed the image to im2txt. <br>4) Document interesting outputs.</ul>
                <br>
                
                <ul><strong>Exercise 4 (pairs): im2xt -> GPT-2</strong><br>1) Use your images as input to im2txt. <br>2) Take the sentence from im2xt and use it as input to GPT-2. <br>3) Document interesting combinations as a single image.</ul>
                <br>
                
                <ul><strong>Exercise 5 (pairs): </strong><br>Upload the most interesting images to <a href="https://docs.google.com/document/d/1gssrlzJDogdWeRHoV09QHERcq5xlOXALei1Mqoah62w/edit">this Google Document</a> under the correct headline.</ul>
                <br>
                
                
                
                <ul><strong>Exercise 6 (individual): </strong><br>Come up with as many ideas as possible for projects that can be build using the models from Runway 20 minutes. You MUST make a least 10 ideas. Each idea should be written on a single small post-it.</ul>
                <br>
                
                <ul><strong>Exercise 7 (work in pairs): </strong><br>Share all your ideas with the person next to you and discuss them. <br> It is okay to come up with more ideas and build on top of each others ideas as you share. <br> In the end pick the best three ideas per person, redo them on a big post-it with a clear descriptive title + a small sketch, so they are easy to read and understand and bring the ideas tomorrow. </ul>
                <br>
                
                
                
                <h2>Examples in p5js</h2>
                <ul>
                    <li><a href="RunwayP5js.zip">Download zip with examples for interfacing Runway from p5js </a></li>
                    <li><a href="https://p5js.org/get-started/">Setting up p5js with a local server</a></li>
                    <li><a href="https://github.com/processing/p5.js/wiki/Local-server">Setting up a local server for p5js </a></li>
                </ul>
                <br>
                
                
                
                <h2>Examples in Processing (optional)</h2>
                <ul>
                    <li><a href="RunwayProcessingExamples.zip">Download zip with examples for interfacing Runway from Processing (optional)</a></li>
                    <li><a href="https://processing.org/download/?processing">Download Processing (optional)</a></li>
                </ul>
                <br>
                
            
                
                
                
        
                
<!--
            <h2>Optional</h2>
                <ul>
                    <li>
                        <a href="https://github.com/AndreasRef/ml4ixd_weki/archive/master.zip" target="_blank">Processing examples for Wekinator</a>
                        <p>Download, unzip and place on desktop.</p>
                    </li>
                    
                    <li>
                        <a href="http://www.wekinator.org/downloads/" target="_blank">Wekinator</a>
                        <p>Download and install.</p>
                    </li>
                    
                    <li>
                        <a href="https://github.com/ml4a/ml4a-ofx/releases/tag/v1.1" target="_blank">ml4a-ofx openFrameworks executables (Mac only!)</a>
                        <p>Download the ml4a-ofx.zip, unzip and place on desktop. Open terminal, navigate to the folder and run <em>sh setup.sh</em></p>
                    </li>
                </ul>
-->
                   
            </section>
            

<!--

            <section>
                <h3>Additional Wekinator links</h3>

                <h4>Make something into a Wekinator input/output</h4>

                <ul>

                    <li>
                        <a href="https://www.youtube.com/watch?v=QLHMtE5XsMs#t=16m30s" target="_blank">Shiffman motion detection video</a>
                    </li>

                    <li>
                        <a href="https://github.com/CodingTrain/Rainbow-Code/blob/master/Tutorials/Processing/11_video/sketch_11_6_MotionDetection/sketch_11_6_MotionDetection.pde" target="_blank">Shiffman motion detection code</a>
                    </li>

                    <li>
                        <a href="makeSomethingIntoWekinatorInput.txt" target="_blank">Turn something into a Wekinator input</a>
                    </li>

                    <li>
                        <a href="makeSomethingIntoWekinatorOutput.txt" target="_blank">Turn something into a Wekinator output</a>
                    </li>
                </ul>

                <br>


                <h4>Additional examples + connected software</h4>

                <ul>
                    <li>
                        <a href="http://www.wekinator.org/examples/" target="_blank">More examples from Wekinators website</a>
                    </li>

                    <li>
                        <a href="https://github.com/fredeerock/wekp5" target="_blank">P5js Wekinator over websockets</a>
                    </li>



                </ul>

                <br>


                <h4>Controlling Wekinator via OSC</h4>

                <ul>
                    <li>
                        <a href="http://www.wekinator.org/detailed-instructions/#Controlling_Wekinator_via_OSC_messages" target="_blank">Detailed instructions page on Wekinators website</a>
                    </li>

                </ul>
                <br>





            </section>


            <section>
                <h2>Slides</h2>
                <ul>
                    <li>
                        <a href="http://stoj.io/ciid/andreas_ciid.pdf" target="_blank">Andreas Refsgaard project slides</a>
                    </li>

                    <li>
                        <a href="WekinatorIntro.pdf" target="_blank">Wekinator slides</a>
                    </li>

                    <li>
                        <a href="RapidMLPrototyping.pdf" target="_blank">Rapid Prototyping Yoga Exercise</a>
                    </li>

                </ul>

            </section>



            <section>
                <h2>Additional resources</h2>


                <ul>
                    <li>
                        <a href="http://ml4a.github.io/" target="_blank">Machine Learning for Artists (ML4A)</a>
                        <p>Community and Github repository</p>
                    </li>
                    <li>
                        <a href="https://medium.com/@atduskgreg/power-to-the-people-how-one-unknown-group-of-researchers-holds-the-key-to-using-ai-to-solve-real-cc9e75b1f334" target="_blank">Power to the People (article)</a>
                        <p>By Greg Borenstein</p>
                    </li>

                    <li>
                        <a href="https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview?imm_mid=0f9b7e&cmp=em-data-na-na-newsltr_20171213&slide=id.g168a3288f7_0_58" target="_blank">Machine Learning 101 slides</a>
                        <p>By Jason Mayes</p>
                    </li>

                    <li>
                        <a href="http://paperspace.com/" target="_blank">Paperspace</a>
                        <p>Cloud computing service for training machine learning models</p>
                    </li>
                    <li>
                        <a href="https://js.tensorflow.org/" target="_blank">Tensorflow.js</a>
                        <p>A WebGL accelerated, browser based JavaScript library</p>
                    </li>
                    <li>
                        <a href="https://developer.leapmotion.com/sdk/v2" target="_blank">Leap Motion SDK</a>
                        <p>Software Development Kit for Leap Motion - needed to run Leap Motion examples</p>
                    </li>
                    <li>
                        <a href="https://p5js.org/" target="_blank">P5.js</a>
                        <p>P5.js a JS client-side version of Processing</p>
                    </li>
                    <li>
                        <a href="https://ml5js.org/" target="_blank">ML5 - Friendly Machine Learning For The Web</a>
                        <p>Machine Learning library for P5.js using tensorflow.js</p>
                    </li>
                    <li>
                        <a href="https://www.doc.gold.ac.uk/eavi/rapidmixapi.com/" target=_blank>Rapid-Mix</a>
                        <p>Toolkit for sensor integration, machine learning &amp; interactive audio (C++ / JS)</p>
                    </li>

                    <li>
                        <a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a>
                        <p>Google AI experiment - Teach a machine to using your camera, live in the browser.</p>
                        <p>The boilerplate (hackable) version of Teachable Machine can be found <a href="https://github.com/googlecreativelab/teachable-machine-boilerplate" target="_blank">here</a>.</p>
                    </li>

                    <li>
                        <a href="https://github.com/nickgillian/ofxGrt" target="_blank">ofxGRT</a>
                        <p>The GRT is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition (openFrameworks)</p>
                    </li>

                    <li>
                        <a href="http://www.wekinator.org/input-helper/" target="_blank">Weki Input Helper</a>
                        <p>The “WekiInputHelper” is a simple application that can sit in between your feature extractor and Wekinator to do common types of processing on your features.</p>
                    </li>
                </ul>
            </section> -->



            <section>

                <h2>Contact Andreas Refsgaard</h2>
                <p><a href="http://andreasrefsgaard.dk">Website</a> / <a href="mailto:mail@andreasrefsgaard.dk">Email</a> / <a href="https://www.facebook.com/andreasrefsgaard">Facebook</a> /&nbsp;<a href="https://twitter.com/AndreasRef">Twitter</a> / <a href="https://www.instagram.com/andreasref/">Instagram</a>  / <a href="https://github.com/AndreasRef">GitHub</a> / <a href="https://vimeo.com/user42241709">Vimeo</a> </p>
                <br>
                <p><a href="http://andreasrefsgaard.dk" target="_blank">Andreas Refsgaard website</a></p>

            </section>

        </div>

    </body>
</html>