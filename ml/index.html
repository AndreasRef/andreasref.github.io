
<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Machine Learning Workshop @AndreasRef</title>
        <meta name="robots" content="noindex, nofollow">
        <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:300,700" rel="stylesheet">
        <link rel="stylesheet" href="main.css">
    </head>
    <body>
        <div id="wrapper">
        
            <h1>Machine Learning Workshop @IxDA Oslo by AndreasRef</h1>
            
<!--
            <p><a href="grupperDMJX.txt" target="_blank">Grupper DMJX uge 2</a></p>
            <p><a href="IntelligentDesign.pdf" target="_blank">Opgave DMJX uge 2</a></p>
-->
            
<!--
            <p><a href="https://we.tl/t-BIxn8Ko4Ga" target="_blank">Andreas intro slides</a></p>


-->


<!--            <p><a href="https://docs.google.com/document/d/1LhUepnOQmyknlATbGRzNk1bStdoW56GvmA7GekxsBgE/edit?usp=sharing" target="_blank">Summary of Tools</a></p>-->
<!--            
            <p><a href="https://docs.google.com/document/d/1wUPngRFJDG0GSYuMTe0gtCQURMENmtE9QSmlPHAj7cs/edit" target="_blank">Course description</a></p>
-->
            
<!--
            <section>
                <p><a href="https://drive.google.com/drive/folders/18szYEYCY3EIQBE9L47rSodMuc332B0o8?usp=sharing">Upload documentation before 14:30</a></p>
            </section>
-->
          
        

            <section>           
<!--
                <h1>Runway Examples for Processing</h1>
                <h3><a href="RunwayProcessingExamples.zip">Download zip</a></h3>
                <br>
-->
                
                <h1>ml5js</h1>
                <h2>Templates, examples and exercises</h2>
                <br>
                
                <h3>0) p5js online editor</h3>
                <ul><a href="https://editor.p5js.org/" target="_blank">Setup an account with the p5js online editor</a></ul>
                <br>

                <h3>1) Train a classification algorithm</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_classifier.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/BJkaHBMYm" target="_blank">Simple template: Webcam classifier</a>. Alternative <a href="https://editor.p5js.org/AndreasRef/sketches/owWCiUho5">press and hold version</a></ul>
                <ul><em>Exercise 1 (individual): Train a classifier to distinguish between two different classes. Make the sketch output a descriptive text for each class.</em></ul> 
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/rJqk5_1aX" target="_blank">Webcam classifier + image</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/ryLlIOJpX" target="_blank">Webcam classifier + sound</a></ul>
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/B19EA7x6Q">Webcam classifier + filter</a></ul>-->
                
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/I0qqnPjfe">Webcam classifier w. 4 classes + save and load</a></ul>-->
                
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/BynhuHsqX" target="_blank">Advanced example: Trainable Camera</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/lUELywyf4" target="_blank">Advanced example: Image Classifier flexible classes + load/save</a></ul>

                <ul><em>Exercise 2 (individual): Try to change the <strong>Webcam classifier + image</strong> example so it outputs images that represent your two classes</em></ul> 
                
<!--                <ul><em>Øvelse 1 (individuel): Træn algoritmen til at skelne mellem to forskellige ting. Ret teksten, så den passer til de to klasser du laver.</em></ul>-->
                
                <br>

                <h3>2) MobileNet pretrained classification</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_mobilenet.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/H1L-KrzFQ" target="_blank">Simple template: Mobilenet pretrained classification</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/Sk8M6mqh7" target="_blank">Advanced example: Classification to speech</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/present/AYNNRbR9A" target="_blank">Advanced example: Poems about things desktop</a> -> <a href="https://editor.p5js.org/AndreasRef/present/kf7Ro9Ceu">mobile</a> -> <a href ="http://andreasrefsgaard.dk/project/poems-about-things/" target="_blank">About the project</a></ul>
                <ul><a href="https://github.com/ml5js/ml5-library/blob/master/src/utils/IMAGENET_CLASSES.js" target="_blank">ImageNet list of classes</a></ul>
                <br>
                <ul><a href="https://modeldepot.github.io/tfjs-yolo-tiny-demo/" target="_blank">Tensorflow.js YOLO multiple object detection (not in p5js editor)</a></ul>
                <ul><img src="yolo_banana_apple.gif"></ul>
                
<!--                <ul><em>Exercise 3 (group): Discuss ideas for projects that use classification</em></ul><br>-->
                
<!--
                <ul><em>Øvelse 2 (to og to): Vælg et eller flere objekter fra <a href="https://github.com/ml5js/ml5-library/blob/master/src/utils/IMAGENET_CLASSES.js" target="_blank">ImageNet list of classes</a> som modellen skal genkende. Prøv at komme på en idé til et koncept, og beskriv hvad der kunne ske, når objektet(/objekterne) bliver detekteret.</em></ul>
                <br>
-->
                
<!--
                <ul><em>Rest of day exercise (group): Vælg en teknik og arbejd videre med den i grupper af tre eller fire. Brug 5-10 minutter på at komme på en idé og resten af tiden til at lave en interaktiv prototype, der viser essensen af jeres koncept. Det er i tilladt at arbejde videre på en af øvelserne fra tidligere. Vær klar til at præsentere kl 14:30.</em></ul>
                <br>
-->
                

                <h3>3) Train a regression algorithm</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_regression.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/Z2OChCuHk" target="_blank">Simple template: Webcam regressor</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/HyEDToYnQ" target="_blank">Advanced example: Playback rate camera</a></ul>
                
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/4K_YGuMik" target="_blank">Advanced example: Control Mister Bean with regression</a></ul>
                <ul><img src="mrBeanGif.gif"></ul>
                
                
                <ul><em>Exercise 3 (individual): Train the regressor and use the continuous output value <strong>slider.value()</strong> to control something. It is okay to leave the code as it is, and just focus on training the system</em></ul><br>
                
<!--
                <ul><em>Øvelse 3 (individuel): Træn regressionsmodellen og benyt output-værdien fra <em>slider.value()</em> til at kontrolleret noget. Det er okay at lade koden være uberørt og kun fokusere på at træne systemet.</em></ul>
                <br>
-->
                
<!--
                <ul><em>Øvelse 3.1 (individuelt): Benyt regressionsoutputtet til at styre et parameter i en visuel p5js skitse. Der kan enten være tale om en skitse I selv laver (men brug ikke for lang tid på at kode), en skitse I har liggende i skuffen (evt i Processing, brug da 5 minutter på at konvertere den til p5js) eller en skitse I finder inde på <a href="https://www.openprocessing.org/" target="_blank">OpenProcessing</a> eller <a href="http://www.generative-gestaltung.de/2/" target="_blank">Generative Gestaltung</a>.</em></ul>
                <br>
                
                <ul><em>Øvelse 3.2 (individuelt): Gentag øvelse 3.1 men lad nu klassifikation (det I lærte i går under (1) Train a classification algorithm)) styre et afspekt ved skitsen. Kodereference: <a href="https://editor.p5js.org/AndreasRef/sketches/nSkzDAZOq">https://editor.p5js.org/AndreasRef/sketches/nSkzDAZOq</a> Inspiration: <a href="https://vimeo.com/175258403">https://vimeo.com/175258403</a>.</em></ul>
                <br>
-->
                
                
                

                <h3>4) PoseNet pose detection</h3>
                <ul><img src="https://ml4a.github.io/images/demos_thumbs/ml5_posenet.jpg"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/g8zrnIlng" target="_blank">Simple template: Webcam PoseNet part selection single users</a></ul>
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/rkz42BzYQ" target="_blank">Simple template: Webcam PoseNet multiple users</a></ul>-->
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/RLv1QbuLa" target="_blank">Advanced example: Classify poses</a></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/r1_w73FhQ" target="_blank">Advanced example: Draw with your nose</a></ul>
                <ul><em>Exercise 4 (group): Pick A or B <br>A) Edit the "Simple template" and use the x-y value of a bodypart to control something  <br>B) Use "Classify poses" as a starting point and make something happen for three different (yoga?) poses</em></ul>
<!--                <ul><em>Øvelse 4 (to og to): A) Forsøg at ændre en af de to "Simple templates" og benyt x-y værdien af en eller flere kropsdele til at kontrollere noget eller B) Tag udgangspunkt i "Classify poses" og træn den til at skelne mellem klasse A og klasse B, evt med et output (tekst/billede etc).</em></ul>-->
                <br>
                
                <h3>5) Beyond ml5js: Sound, speech and face</h3>
                <ul><img src="face_emotions.png"></ul>
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/2ElDbMuHT" target="_blank">Pretrained Facial Emotions (with clm tracker)</a></ul>
<!--                <ul><a href="https://andreasref.github.io/kochi/face_knn/index.html" target="_blank">KNN Facial Expressions (not in p5js editor - takes 30 seconds to load)</a> -> <a href="https://andreasref.github.io/ml5js/face_knn.zip">download zip</a> </ul>-->
                <ul><a href="https://andreasref.github.io/ml/Face-Detection-JavaScript_web/" target="_blank">Facetracking + estimates of age, gender and mood with face-api</a> <em><a href="https://github.com/AndreasRef/andreasref.github.io/tree/master/ml/Face-Detection-JavaScript_web">source code (not in p5js editor)</a></em></ul>
<!--                <ul><img src="faceExpression.png"></ul>-->
                
                
<!--                <ul><a href="https://kylemcdonald.github.io/cv-examples/" target="_blank">Kyle McDonald Computer Vision examples</a></ul>-->
                
                
<!--
                <ul><em>Øvelse 5A (individuel): Kom på en sjov idé hvor I benytter værdien for en eller flere af de fire følelser (angry, sad, surprised eller happy) til at kontrollere noget i en p5js skitse.</em></ul>
                <br>
-->
                <ul><em>Exercise 5A (individual): Use one of the values from the four emotions (angryVal, sadVal, surprisedVal or happyVal) from the "Pretrained Facial Emotions" example to control something.</em></ul>
                <br>
                
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/5DHTu_cQm" target="_blank">KNN MFCCs sound classification (with meyda.js)</a></ul>-->
                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/DTNxwVdxf" target="_blank">Speech recognition (with annyang.js)</a></ul>
                
<!--                <ul><a href="https://editor.p5js.org/AndreasRef/sketches/25DZ20Onw">KNN Facial Expressions (with clm tracker)</a></ul>-->
                
                
<!--
                <ul><em>Øvelse 5B (to og to): Diskuter idéer til et projekt I ville kunne bygge med speech recognition og p5js, fx et spil, en service, et kampagnesite eller noget helt fjerde. Begynd på at bygge de simpleste dele, og se hvor langt I kan nå med det.</em></ul>
                <br>
-->
                <ul><em>Exercise 5B (groups): Discuss ideas for a project you could build using speech recognition (a game, a service a campaign site or something else) and try to build a small part of it to prove the interaction.</em></ul>
                <br>
                
<!--
                <br>
                <ul><em>Exercise 5 (group): Use one of the three templates above as a starting point for making an interactive sketch that you control with sounds, speech or facial expressions.</em></ul>
                <br>
-->
                
<!--
                <ul><em>Exercise 6 (individual): <br>Come up with as many ideas as possible for projects that can be build using the techniques you have learned so far in 15 minutes. You MUST make a least 10 ideas, and at least 1 idea for each of the five headlines: <br> 1) Train your own classification <br> 2) Pretrained classification <br> 3) Regression <br> 4) PoseNet <br> 5) Sound, speech and face <br><br> Each idea should be written on a single small post-it.</em></ul>
                <br>
                
-->
<!--
                <ul><em>Exercise 6 (individual): <br>Come up with as many ideas as possible for projects that can be build using the techniques you have learned so far in 10 minutes. You MUST make a least 5 ideas. Each idea should be written on a single post-it with a descriptive title and a sketch and/or simple explanation.</em></ul>
                <br>
-->
                
<!--
                <ul><em>Exercise 6 (group): <br>Spend the rest of today on coming up with a concept and making a small interactive demo using one of the techniques learned so far. Work in groups or alone. It is okay to build on top of work done at a previous exercise. Informal mini-presentations start at 16:30.</em></ul>
                <br>
-->
                <h3>6) Start prototyping!</h3>
                <ul><em>Exercise 6 (group):
                    
                    <br>Spend the rest of today coming up with a concept and build a small prototype that shows a key interaction. You can make something creative, useful and/or silly - up to you - just make sure it has a machine learning component somewhere! Informal mini-presentations start at 13:00.</ul>
<!--
                    <ul>Not sure what to build? Perhaps you could try to tackle one of the <a href="https://www.un.org/sustainabledevelopment/sustainable-development-goals/" target="_blank">UN Sustainable Development Goals</a>. Here is a bit of <a href="ungoals.html" target="_blank">inspiration</a> for goal 11, 12 and 13</ul></em>
                    <img src="un.png" width="600" style="margin:50px">
-->
                <br>
                
<!--                <ul><em>Exercise 7 (work in pairs): <br>Share all your ideas with the person next to you and discuss them. <br> It is okay to come up with more ideas and build on top of each others ideas as you share. <br> In the end pick the best three ideas per person, redo them on a big post-it with a clear descriptive title + a small sketch, so they are easy to read and understand. </em></ul>-->
                <br>
                <h3>Having issues running the examples?</h3>
                <ul>Make sure you are running them in <a href="https://www.google.com/chrome/" target="_blank">Google Chrome</a></ul>
                <ul><a href="https://support.google.com/chrome/answer/2693767?co=GENIE.Platform%3DDesktop&hl=en&oco=0" target="_blank">Allow camera and microphone in Google Chrome</a></ul>
                <ul><a href="https://support.apple.com/guide/mac-help/control-access-to-your-camera-on-mac-mchlf6d108da/mac" target="_blank">Allow camera on MacOSX in System Preferences</a></ul>
                <ul>Webcam access on Windows 10: Select Start > Settings > Privacy > Camera. Set "Let apps use my camera" to "On". Make sure Chrome has access to use the camera.</ul>
                <ul>Older computers with less powerfull graphics cards might run out of memory if you record hundreds or thousands of examples from the webcam, especially on Windows. If it happens, switch to another computer or be more modest when recording training data.</ul>
                <br>
                
                <h3>Other links</h3>
                <ul><a href="https://ml5js.org/docs/quick-start">Documentation + more examples on ml5js.org</a></ul>
                <ul><a href="https://github.com/ml5js/ml5-examples/tree/master/javascript">ml5 examples in clean javaScript without p5js</a></ul>
                <ul><a href="https://js.tensorflow.org/" target="_blank">Tensorflow.js website</a></ul>
                <ul><a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a></ul>
                <ul><a href="https://runwayml.com/" target="_blank">Runway</a></ul>                
                <ul><a href="https://github.com/justadudewhohacks/face-api.js?files=1" target="_blank">face-api.js</a></ul>
                <ul><a href="http://genekogan.com/" target="_blank">Gene Kogan</a></ul>
                <ul><a href="http://booksby.ai/" target="_blank">BooksBy.Ai</a></ul>
                <ul><a href="https://cloud.google.com/vision/#vision-api-demo" target="_blank">Google Cloud Vision</a></ul>
                <ul><a href="https://natural-language-understanding-demo.ng.bluemix.net/" target="_blank">IBM Watson Natural Language Understanding</a></ul>
                <ul><a href="https://runwayml.com/" target="_blank">Runway ML</a></ul>
<!--                <ul><a href="https://booksby.ai/" target="_blank">Books by AI</a></ul>-->
                
                <br>
                <ul><a href="https://editor.p5js.org/" target="_blank">Official p5.js editor</a></ul>
                <ul><a href="https://p5js.org/reference/" target="_blank">Official p5.js reference</a></ul>
                <ul><a href="https://andreasref.github.io/malmedkodning/index.html" target="_blank">Examples for p5.js aimed at beginners</a></ul>    
    
                <br>
            </section>
            
<!--
            <section>
                <h1>Day 2: Wekinator</h1>
                <p><a href="https://github.com/j3nsykes/CIID_19" target="_blank">Link to day two code + website</a></p>
            </section>    
-->

            
<!--
            <section>
                <h1>Day 3: Runway</h1>
                
                <h2>Downloads</h2>
                <ul>
                    <li>
                        <a href="https://runwayapp.ai/beta/get/">Runway</a>
                        <p>Download and install Runway. You should have recieved an invitation over email on Tuesday. Use that email address to set up your account. If you haven't <a href="mailto:mail@andreasrefsgaard.dk">let us know!</a></p>
                        <p>Please follow the <a href="https://docs.runwayapp.ai/#/installation">Installation guide</a> to make sure you are all setup before we start.</p>
                        <p>Once Runway is installed with Docker, you can install the models you want to play with in the workshop. Install <strong>im2txt</strong> (required) and any other models you feel like and have space for on your computer. See step 1 and 2 from <a href="https://docs.runwayapp.ai/#/tutorial_t2i">this tutorial</a> for how to install models.</p>
                        
                        <p><a href="sampleImages.zip">Small zip with mixed images from ImageNet</a></p>
                        
                    </li>
                </ul>
                <br>
                
                <h2>Exercises</h2>
                
                <ul><strong>Exercise 1 (individual):</strong><br> Find 10 images either online or on your computer that you want to run through the different models in Runway and place them in a folder. Try to pick images that are not all too similar, and perhaps pick different styles of images (press photos, paintings, images from pop culture, personal photos).</ul>
                <br>
                
                <ul><strong>Exercise 2 (pairs): im2txt -> AttnGAN</strong><br>1) Use your images as input to im2txt. <br>2) Use the line of text from im2txt as input for AttnGAN. <br>3) Document interesting combinations.</ul>
                <br>
                
                <ul><strong>Exercise 3 (pairs): AttnGAN -> im2xt </strong><br>1) Write a sentence and make AttnGAN output an image. <br>2) Save the image to your computer. <br>3) Feed the image to im2txt. <br>4) Document interesting outputs.</ul>
                <br>
                
                <ul><strong>Exercise 4 (pairs): im2xt -> GPT-2</strong><br>1) Use your images as input to im2txt. <br>2) Take the sentence from im2xt and use it as input to GPT-2. <br>3) Document interesting combinations as a single image.</ul>
                <br>
                
                <ul><strong>Exercise 5 (pairs): </strong><br>Upload the most interesting images to <a href="https://docs.google.com/document/d/1-P9ZsnGxqTpZ2Fnq8Fvaov2pSt8QHvB5BES4R5SpKy0/edit?usp=sharing">this Google Document</a> under the correct headline.</ul>
                <br>
                
                

                
                <ul><strong>Exercise 6 (individual): </strong><br>Explore all the models in Runway that you have not tried yet and come up with as many ideas as possible for projects that can be build using the models from Runway. You MUST make a least 10 ideas, give each idea a title and a description and/or a drawing.</ul>
                <br>
                
                <ul><strong>Exercise 7 (work in pairs): </strong><br>Share  your ideas with the person next to you and discuss them. <br> It is okay to come up with more ideas and build on top of each others ideas as you share. <br> In the end pick the best three ideas per person, redo them on a big post-it/piece of paper with a clear descriptive title + a small sketch, so they are easy to read and understand and bring the ideas monday. </ul>
                <br>
                

                

                <h2>Examples for Runway in p5js</h2>
                <ul>
                    <li><a href="RunwayP5js.zip">Download zip with examples for interfacing Runway from p5js </a></li>
                    <li><a href="https://p5js.org/get-started/">Setting up p5js with a local server</a></li>
                    <li><a href="https://github.com/processing/p5.js/wiki/Local-server">Setting up a local server for p5js </a></li>
                </ul>
                <br>

                
                
                

                <h2>Examples for Runway in Processing (optional)</h2>
                <ul>
                    <li><a href="RunwayProcessingExamples.zip">Download zip with examples for interfacing Runway from Processing (optional)</a></li>
                    <li><a href="https://processing.org/download/?processing">Download Processing (optional)</a></li>
                </ul>
                <br>

                
            
-->
                
                
                
        
                
<!--
            <h2>Optional</h2>
                <ul>
                    <li>
                        <a href="https://github.com/AndreasRef/ml4ixd_weki/archive/master.zip" target="_blank">Processing examples for Wekinator</a>
                        <p>Download, unzip and place on desktop.</p>
                    </li>
                    
                    <li>
                        <a href="http://www.wekinator.org/downloads/" target="_blank">Wekinator</a>
                        <p>Download and install.</p>
                    </li>
                    
                    <li>
                        <a href="https://github.com/ml4a/ml4a-ofx/releases/tag/v1.1" target="_blank">ml4a-ofx openFrameworks executables (Mac only!)</a>
                        <p>Download the ml4a-ofx.zip, unzip and place on desktop. Open terminal, navigate to the folder and run <em>sh setup.sh</em></p>
                    </li>
                </ul>
-->
                   
<!--            </section>-->
            

<!--

            <section>
                <h3>Additional Wekinator links</h3>

                <h4>Make something into a Wekinator input/output</h4>

                <ul>

                    <li>
                        <a href="https://www.youtube.com/watch?v=QLHMtE5XsMs#t=16m30s" target="_blank">Shiffman motion detection video</a>
                    </li>

                    <li>
                        <a href="https://github.com/CodingTrain/Rainbow-Code/blob/master/Tutorials/Processing/11_video/sketch_11_6_MotionDetection/sketch_11_6_MotionDetection.pde" target="_blank">Shiffman motion detection code</a>
                    </li>

                    <li>
                        <a href="makeSomethingIntoWekinatorInput.txt" target="_blank">Turn something into a Wekinator input</a>
                    </li>

                    <li>
                        <a href="makeSomethingIntoWekinatorOutput.txt" target="_blank">Turn something into a Wekinator output</a>
                    </li>
                </ul>

                <br>


                <h4>Additional examples + connected software</h4>

                <ul>
                    <li>
                        <a href="http://www.wekinator.org/examples/" target="_blank">More examples from Wekinators website</a>
                    </li>

                    <li>
                        <a href="https://github.com/fredeerock/wekp5" target="_blank">P5js Wekinator over websockets</a>
                    </li>



                </ul>

                <br>


                <h4>Controlling Wekinator via OSC</h4>

                <ul>
                    <li>
                        <a href="http://www.wekinator.org/detailed-instructions/#Controlling_Wekinator_via_OSC_messages" target="_blank">Detailed instructions page on Wekinators website</a>
                    </li>

                </ul>
                <br>





            </section>


            <section>
                <h2>Slides</h2>
                <ul>
                    <li>
                        <a href="http://stoj.io/ciid/andreas_ciid.pdf" target="_blank">Andreas Refsgaard project slides</a>
                    </li>

                    <li>
                        <a href="WekinatorIntro.pdf" target="_blank">Wekinator slides</a>
                    </li>

                    <li>
                        <a href="RapidMLPrototyping.pdf" target="_blank">Rapid Prototyping Yoga Exercise</a>
                    </li>

                </ul>

            </section>



            <section>
                <h2>Additional resources</h2>


                <ul>
                    <li>
                        <a href="http://ml4a.github.io/" target="_blank">Machine Learning for Artists (ML4A)</a>
                        <p>Community and Github repository</p>
                    </li>
                    <li>
                        <a href="https://medium.com/@atduskgreg/power-to-the-people-how-one-unknown-group-of-researchers-holds-the-key-to-using-ai-to-solve-real-cc9e75b1f334" target="_blank">Power to the People (article)</a>
                        <p>By Greg Borenstein</p>
                    </li>

                    <li>
                        <a href="https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview?imm_mid=0f9b7e&cmp=em-data-na-na-newsltr_20171213&slide=id.g168a3288f7_0_58" target="_blank">Machine Learning 101 slides</a>
                        <p>By Jason Mayes</p>
                    </li>

                    <li>
                        <a href="http://paperspace.com/" target="_blank">Paperspace</a>
                        <p>Cloud computing service for training machine learning models</p>
                    </li>
                    <li>
                        <a href="https://js.tensorflow.org/" target="_blank">Tensorflow.js</a>
                        <p>A WebGL accelerated, browser based JavaScript library</p>
                    </li>
                    <li>
                        <a href="https://developer.leapmotion.com/sdk/v2" target="_blank">Leap Motion SDK</a>
                        <p>Software Development Kit for Leap Motion - needed to run Leap Motion examples</p>
                    </li>
                    <li>
                        <a href="https://p5js.org/" target="_blank">P5.js</a>
                        <p>P5.js a JS client-side version of Processing</p>
                    </li>
                    <li>
                        <a href="https://ml5js.org/" target="_blank">ML5 - Friendly Machine Learning For The Web</a>
                        <p>Machine Learning library for P5.js using tensorflow.js</p>
                    </li>
                    <li>
                        <a href="https://www.doc.gold.ac.uk/eavi/rapidmixapi.com/" target=_blank>Rapid-Mix</a>
                        <p>Toolkit for sensor integration, machine learning &amp; interactive audio (C++ / JS)</p>
                    </li>

                    <li>
                        <a href="https://teachablemachine.withgoogle.com/" target="_blank">Teachable Machine</a>
                        <p>Google AI experiment - Teach a machine to using your camera, live in the browser.</p>
                        <p>The boilerplate (hackable) version of Teachable Machine can be found <a href="https://github.com/googlecreativelab/teachable-machine-boilerplate" target="_blank">here</a>.</p>
                    </li>

                    <li>
                        <a href="https://github.com/nickgillian/ofxGrt" target="_blank">ofxGRT</a>
                        <p>The GRT is a cross-platform, open-source, C++ machine learning library designed for real-time gesture recognition (openFrameworks)</p>
                    </li>

                    <li>
                        <a href="http://www.wekinator.org/input-helper/" target="_blank">Weki Input Helper</a>
                        <p>The “WekiInputHelper” is a simple application that can sit in between your feature extractor and Wekinator to do common types of processing on your features.</p>
                    </li>
                </ul>
            </section> -->



            <section>

                <h2>Contact Andreas Refsgaard</h2>
                <p><a href="http://andreasrefsgaard.dk">Website</a> / <a href="mailto:mail@andreasrefsgaard.dk">Email</a> / <a href="https://www.facebook.com/andreasrefsgaard">Facebook</a> /&nbsp;<a href="https://twitter.com/AndreasRef">Twitter</a> / <a href="https://www.instagram.com/andreasref/">Instagram</a>  / <a href="https://github.com/AndreasRef">GitHub</a> / <a href="https://vimeo.com/user42241709">Vimeo</a> </p>

            </section>

        </div>

    </body>
</html>